The following Venn diagram shows the intersection of the probability of two events. LetÂ ğ¸Â andÂ ğ¹Â be events.

![](../public/33ec5e94b36cdcf515967bbb659d0c70.png)

Then, we may expressÂ ğ¸Â as

$$ğ¸=ğ¸ğ¹âˆªğ¸ğ¹â€²$$

for, in order for a point to be inÂ ğ¸, it must either be in bothÂ ğ¸Â andÂ ğ¹Â or be inÂ ğ¸Â but not inÂ ğ¹. AsÂ ğ¸ğ¹Â andÂ ğ¸ğ¹â€²Â  are clearly mutually exclusive, we haveÂ ğ‘ƒ(ğ¸)Â as

$$ğ‘ƒ(ğ¸)=ğ‘ƒ(ğ¸ğ¹)+ğ‘ƒ(ğ¸ğ¹â€²)$$$$=ğ‘ƒ(ğ¸|ğ¹)ğ‘ƒ(ğ¹)+ğ‘ƒ(ğ¸|ğ¹â€²)ğ‘ƒ(ğ¹â€²)$$$$=ğ‘ƒ(ğ¸|ğ¹)ğ‘ƒ(ğ¹)+ğ‘ƒ(ğ¸|ğ¹â€²)[1âˆ’ğ‘ƒ(ğ¹)]$$

The probability of the eventÂ ğ¸Â is a weighted average of the conditional probability ofÂ ğ¸Â given thatÂ ğ¹Â has occurred and the conditional probability ofÂ ğ¸Â given thatÂ ğ¹Â has not occurred.

Each conditional probability is given as much weight as the event it is conditioned on to occur. It is an extremely useful formula, for its use often enables us to determine the probability of an event by first 'conditioning' on whether or not some second event has occurred. There are many instances where it is difficult to compute the probability of an event directly. Still, it is straightforward to compute it once we know whether or not some second event has occurred.

The formula for the Bayes theorem can be written in a variety of ways. The following is the most common version:

$$ğ‘ƒ(ğ´âˆ£ğµ)=\frac{ğ‘ƒ(ğ´)ğ‘ƒ(ğµâˆ£ğ´)}{ğ‘ƒ(ğµ)}$$

$ğ‘ƒ(ğ´âˆ£ğµ)$Â is the conditional probability of eventÂ ğ´Â occurring, given thatÂ ğµÂ is true.

$ğ‘ƒ(ğµâˆ£ğ´)$Â is the conditional probability of eventÂ ğµÂ occurring, given thatÂ ğ´Â is true.

ğ‘ƒ(ğ´)Â andÂ ğ‘ƒ(ğµ)Â are the probabilities ofÂ ğ´Â andÂ ğµÂ occurring independently of one another.

This can also be expanded and written for n mutually exclusive eventsÂ $ğ´1,ğ´2,â€¦,ğ´ğ‘›$ whose union is the sample space S. Let B be any given event. Then Bayesâ€™ theorem states

$$ğ‘ƒ(ğ´|ğµ)=\frac{ğ‘ƒ(ğ´_ğ‘–)ğ‘ƒ(ğµ|ğ´_ğ‘–)}{\sum^ğ‘›_{ğ‘–=1}ğ‘ƒ(ğ´ğ‘–)ğ‘ƒ(ğµ|ğ´_ğ‘–)};ğ‘–=1,2,...,ğ‘›$$

whereÂ $ğ‘ƒ(ğ´1),ğ‘ƒ(ğ´2),â€¦,ğ‘ƒ(ğ´ğ‘›)$Â are called theÂ **prior probabilities**Â ofÂ $ğ´1,ğ´2,â€¦,ğ´ğ‘›$Â  andÂ $ğ‘ƒ(ğ´1|ğµ),ğ‘ƒ(ğ´2|ğµ),â€¦,ğ‘ƒ(ğ´ğ‘›|ğµ)$Â are called theÂ **posterior probabilities**Â  ofÂ $ğ´1,ğ´2,â€¦,ğ´ğ‘›$. Also, note that the sum of all the posterior probabilities must equalÂ 1.